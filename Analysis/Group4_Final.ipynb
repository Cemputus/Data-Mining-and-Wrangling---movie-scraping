{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Group 4 Data Mining And Wrangling Test2**\n",
    "\n",
    "### **Data source:** *https://www.imdb.com/chart/top/*\n",
    "#### We used used different methods to get the get the data but we concluded with the *Top 250 Movies* from IMDB using Scrapy and spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as mns \n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "import json\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we saved the dataset as a JSON file, We had to convert it to csv format removing the the [] and [[]] formats (lists and nested lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the JSON file\n",
    "json_file_path = \"IMDB_250_movies.json\"\n",
    "\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert list values to plain values\n",
    "for movie in data:\n",
    "    for key, value in movie.items():\n",
    "        if isinstance(value, list):\n",
    "            if all(isinstance(i, list) for i in value):  # If nested lists exist, flatten them\n",
    "                movie[key] = \", \".join([\", \".join(map(str, sublist)) for sublist in value])\n",
    "            else:\n",
    "                movie[key] = \", \".join(map(str, value))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save as CSV\n",
    "csv_file_path = \"IMDB_250_movies.csv\"\n",
    "df.to_csv(csv_file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the csv Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the csv dataset \n",
    "df = pd.read_csv(\"IMDB_250_movies.csv\")\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking the shape of the dataset for information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use the OMDB API to get the other attributes of the dataset i.e. Main Actors, Budget, Box Office Gross, and Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMDb API Key\n",
    "OMDB_API_KEY = \"60fded84\"\n",
    "\n",
    "# Function to fetch movie details from OMDb API\n",
    "def fetch_movie_details(title):\n",
    "    url = f\"http://www.omdbapi.com/?t={title}&apikey={OMDB_API_KEY}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if the response is valid\n",
    "        if data.get(\"Response\") == \"True\":\n",
    "            return {\n",
    "                \"title\": data.get(\"Title\", title),  # Ensure title matches\n",
    "                \"Cast (Main Actors)\": data.get(\"Actors\", \"N/A\"),\n",
    "                \"Budget\": \"N/A\",  # OMDb does not provide budget info\n",
    "                \"Box Office Gross\": data.get(\"BoxOffice\", \"N/A\"),\n",
    "                \"Awards\": data.get(\"Awards\", \"N/A\")\n",
    "            }\n",
    "    \n",
    "    # If no valid response, return empty data\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"Cast (Main Actors)\": \"N/A\",\n",
    "        \"Budget\": \"N/A\",\n",
    "        \"Box Office Gross\": \"N/A\",\n",
    "        \"Awards\": \"N/A\"\n",
    "    }\n",
    "\n",
    "# Load your existing CSV file\n",
    "existing_csv = \"IMDB_250_movies.csv\"\n",
    "df = pd.read_csv(existing_csv)\n",
    "\n",
    "# Fetch details for each movie\n",
    "additional_data = [fetch_movie_details(title) for title in df[\"title\"]]\n",
    "\n",
    "# Convert the fetched data into a DataFrame\n",
    "extra_df = pd.DataFrame(additional_data)\n",
    "\n",
    "# Merge with the existing DataFrame\n",
    "df = df.merge(extra_df, on=\"title\", how=\"left\")\n",
    "\n",
    "# Save updated data\n",
    "new_df_path = \"Final_IMDB_250_movies_with_OMDB.csv\"\n",
    "df.to_csv(new_df_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Updated CSV saved at: {new_df_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Final_IMDB_250_movies_with_OMDB.csv\")\n",
    "\n",
    "df1.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizing the Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### checking for missing values in the Box Office column\n",
    "mns.bar(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### checking for missing values in the Box Office column\n",
    "missing_values = df1.isnull().sum()\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping the Budget column\n",
    "#The Budget column is not necessary for the analysis since it is only missing values, so we can drop it from the data frame.\n",
    "\n",
    "df2 = df1.drop(columns=[\"Budget\"])\n",
    "\n",
    "df2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking the missing values in the dataset\n",
    "\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping the missing values\n",
    "#Since the missing values are few, we can drop them from the dataset.\n",
    "df3 = df2.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the missing values in the dataset again\n",
    "df3.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Now we can save the data as a new dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving df3 to a new file\n",
    "df3.to_csv(\"IMDB_250_movies_cleaned2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the cleaned data\n",
    "cleaned_data = pd.read_csv('IMDB_250_movies_cleaned2.csv')\n",
    "cleaned_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the release_day, month, and year to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[['release_day','release_month','release_year']] = cleaned_data[['release_day','release_month','release_year']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now convert the release day, month, and year to day-month-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['date'] = pd.to_datetime(cleaned_data['release_year'] + '-' +  cleaned_data['release_month'] + '-'+ cleaned_data['release_day'])\n",
    "cleaned_data['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert the release_month to the month name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['Release_Month_name'] = cleaned_data.date.dt.month_name()\n",
    "cleaned_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the release_week_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_data['Release_week_day'] = cleaned_data.date.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## viewing the dataframe\n",
    "cleaned_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## column names\n",
    "cleaned_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['Release_Week_day'] = cleaned_data.Date.dt.day_name()\n",
    "cleaned_data['Release_Month']    = cleaned_data.Date.dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.columns"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
